{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task 3\n"
      ],
      "metadata": {
        "id": "GfBs7x70yVsg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwvR51ynqz7H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "link = \"https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv\"\n",
        "df = pd.read_csv(link)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Info"
      ],
      "metadata": {
        "id": "A688eeBD7UI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The total number of documents in the dataset:\", len(df))\n",
        "print(\"The total number of documents per class:\")\n",
        "print(df['category'].value_counts())\n",
        "print(\"One sample document per class\")\n",
        "for c in df[\"category\"].unique():\n",
        "    print(f\"\\nClass = {c} \")\n",
        "    print(df[df[\"category\"] == c][\"text\"].iloc[0][:200])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lTWRv86rYMW",
        "outputId": "29917f05-174a-4789-f30e-6595fcd9d277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of documents in the dataset: 2225\n",
            "The total number of documents per class:\n",
            "category\n",
            "sport            511\n",
            "business         510\n",
            "politics         417\n",
            "tech             401\n",
            "entertainment    386\n",
            "Name: count, dtype: int64\n",
            "One sample document per class\n",
            "\n",
            "Class = tech \n",
            "tv future in the hands of viewers with home theatre systems  plasma high-definition tvs  and digital video recorders moving into the living room  the way people watch tv will be radically different in\n",
            "\n",
            "Class = business \n",
            "worldcom boss  left books alone  former worldcom boss bernie ebbers  who is accused of overseeing an $11bn (£5.8bn) fraud  never made accounting decisions  a witness has told jurors.  david myers made\n",
            "\n",
            "Class = sport \n",
            "tigers wary of farrell  gamble  leicester say they will not be rushed into making a bid for andy farrell should the great britain rugby league captain decide to switch codes.   we and anybody else inv\n",
            "\n",
            "Class = entertainment \n",
            "ocean s twelve raids box office ocean s twelve  the crime caper sequel starring george clooney  brad pitt and julia roberts  has gone straight to number one in the us box office chart.  it took $40.8m\n",
            "\n",
            "Class = politics \n",
            "howard hits back at mongrel jibe michael howard has said a claim by peter hain that the tory leader is acting like an  attack mongrel  shows labour is  rattled  by the opposition.  in an upbeat speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The document is not that well balanced from the observation above, as sports has the highest no of documents,511, while Entertainment has only 386 documents"
      ],
      "metadata": {
        "id": "Ysbz0Ehs8GVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train,Text split"
      ],
      "metadata": {
        "id": "QbM-GnkwyL9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  train_test_split(data,t_ratio=0.2):\n",
        "    size = int(len(data) * t_ratio)\n",
        "    test = data[:size]\n",
        "    train = data[size:]\n",
        "    print(test.head(5))\n",
        "    print(train.head(5))\n",
        "    return train, test\n",
        "\n",
        "train_data,test_data=train_test_split(df,0.2)\n",
        "training=list(zip(train_data['text'], train_data['category']))\n",
        "testing=list(zip(test_data['text'], test_data['category']))\n",
        "print(len(training))\n",
        "print(len(testing))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv_9-By_rpx5",
        "outputId": "c3e5723f-427b-45fe-b6b4-6a3b957b46cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        category                                               text\n",
            "0           tech  tv future in the hands of viewers with home th...\n",
            "1       business  worldcom boss  left books alone  former worldc...\n",
            "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
            "3          sport  yeading face newcastle in fa cup premiership s...\n",
            "4  entertainment  ocean s twelve raids box office ocean s twelve...\n",
            "     category                                               text\n",
            "445  politics  hunt ban support is  in decline  support for a...\n",
            "446      tech  broadband challenges tv viewing the number of ...\n",
            "447  business  weak data buffets french economy a batch of do...\n",
            "448     sport  collins calls for chambers return world 100m c...\n",
            "449  business  nasdaq planning $100m-share sale the owner of ...\n",
            "1780\n",
            "445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the model"
      ],
      "metadata": {
        "id": "CdMsmtZ0yTDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "classifier = NaiveBayesClassifier(training)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nNPqEdetVMA",
        "outputId": "81ddf75d-aad7-4c42-e994-d6eff595dc4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy"
      ],
      "metadata": {
        "id": "7AhLEo8eyRCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.accuracy(testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-5MIwXow718",
        "outputId": "d280cfbe-a208-47c7-c0e0-a55d1405456b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9595505617977528"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-fold cross validation"
      ],
      "metadata": {
        "id": "J1zNARtbyztI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "def cross_validation_split(dataset, k):\n",
        "    kf = KFold(n_splits=k, shuffle=False, random_state=None)\n",
        "    kfolds = []\n",
        "    for train_idx, test_idx in kf.split(dataset):\n",
        "        train_df = dataset.iloc[train_idx]\n",
        "        test_df = dataset.iloc[test_idx]\n",
        "        kfolds.append((train_df, test_df))\n",
        "    return kfolds\n",
        "\n",
        "\n",
        "kfolddata = cross_validation_split(df, k=2)\n",
        "for i, (train_df, test_df) in enumerate(kfolddata):\n",
        "    print(f\"\\nFold {i+1}\")\n",
        "    print(\"Train size:\", len(train_df))\n",
        "    print(\"Test size:\", len(test_df))\n",
        "    train_data = list(zip(train_df[\"text\"], train_df[\"category\"]))\n",
        "    test_data = list(zip(test_df[\"text\"], test_df[\"category\"]))\n",
        "    classifier = NaiveBayesClassifier(train_data)\n",
        "    acc = classifier.accuracy(test_data)\n",
        "    print(\"Accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW8R9ebx10bm",
        "outputId": "d9a2caa3-d3f1-400e-93e4-4ef941ab6e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "Train size: 1112\n",
            "Test size: 1113\n",
            "Accuracy: 0.9604672057502246\n",
            "\n",
            "Fold 2\n",
            "Train size: 1113\n",
            "Test size: 1112\n",
            "Accuracy: 0.9460431654676259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task4\n"
      ],
      "metadata": {
        "id": "J_ENJWzm2smm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "\n",
        "\n",
        "def naiveBayesClassifier(trainingSet,testSet):\n",
        "    classifier = NaiveBayesClassifier(trainingSet)\n",
        "    correct = 0\n",
        "    total = len(testSet)\n",
        "    for doc, clas in testSet:\n",
        "        predicted = classifier.classify(doc)\n",
        "        print(f\"document: ('{doc}', '{clas}')\\t predicted class: {predicted}\\n\")\n",
        "        if predicted == clas:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "trainingSet = [('London is the Capital of GB','GB'),\n",
        "               ('Oxford is a city in GB','GB'),\n",
        "               ('Dublin is the capital of Ireland','IE'),\n",
        "               ('Limerick is a city in Ireland','IE')]\n",
        "testSet = [('University of Limerick','IE'),\n",
        "           ('University College Dublin','IE'),\n",
        "           ('Imperial College London','GB'),\n",
        "           ('University of Oxford','GB'),\n",
        "           ('Ireland & GB','IE')]\n",
        "\n",
        "\n",
        "naiveBayesClassifier(trainingSet,testSet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdpiQpnJz49Y",
        "outputId": "7b84a5a7-14dc-4fee-c9cf-3b3416dfb5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "document: ('University of Limerick', 'IE')\t predicted class: IE\n",
            "\n",
            "document: ('University College Dublin', 'IE')\t predicted class: IE\n",
            "\n",
            "document: ('Imperial College London', 'GB')\t predicted class: GB\n",
            "\n",
            "document: ('University of Oxford', 'GB')\t predicted class: GB\n",
            "\n",
            "document: ('Ireland & GB', 'IE')\t predicted class: IE\n",
            "\n",
            "Accuracy: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " C. explain why the class of the last test document is predicted to be “GB” or “Ireland”\n",
        "\n",
        " Since the last document contain \"Ireland\" and \"GB\", they are present in both the classes,( Ireland in IE and GB in GB) hence the last document gets predicted as either \"GB\" or \"IE\". And the last document doesnt contain any another word to correctly predict it as either of those documents(\"&\" doesnt belong to the dictionary)."
      ],
      "metadata": {
        "id": "w3srfj4e43Oi"
      }
    }
  ]
}