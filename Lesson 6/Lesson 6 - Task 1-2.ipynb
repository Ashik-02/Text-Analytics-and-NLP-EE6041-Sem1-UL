{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task 1\n"
      ],
      "metadata": {
        "id": "kIemmOGmn9sg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.a"
      ],
      "metadata": {
        "id": "IjClGarCoFHe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqRfrxQak6LX",
        "outputId": "7e8a84e9-7f2e-4a94-8836-a2211282230b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "posCount = 2\n",
            "negCount = 2\n",
            "ProbPos= 0.5\n",
            "ProbNeg= 0.5\n",
            "{'great': 4, 'and': 1, 'scenes': 1, 'plot': 1, 'satire': 1, 'a': 1, 'twists': 1, 'film': 1} total lenght 11\n",
            "{'great': 1, 'was': 1, 'scenes': 1, 'boxing': 1, 'plot': 1, 'disappointment': 1, 'or': 1, 'no': 1, 'a': 1, 'scene': 1, 'twists': 1} total lenght 11\n",
            "V= {'great', 'was', 'and', 'scenes', 'boxing', 'plot', 'disappointment', 'or', 'satire', 'no', 'a', 'scene', 'twists', 'film'}\n",
            "|V|=14\n",
            "-----------------------------------------------------------------------\n",
            "Text document = ('great disappointment indeed ','?')\n",
            "  word = \"great\" , wordconditionalProbPos = 0.200000 ,\t wordconditionalProbNeg = 0.080000\n",
            "  word = \"disappointment\" , wordconditionalProbPos = 0.040000 ,\t wordconditionalProbNeg = 0.080000\n",
            "  word = \"indeed\" , wordconditionalProbPos = Ignore ,\t wordconditionalProbNeg = Ignore\n",
            "\n",
            " docProbPos = 0.004000 docProbneg = 0.003200\n",
            "  Inferred class =  +\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def multinomialNaiveBayesClassifier(trainingSet,testSet):\n",
        "    postcount,negcount=0,0\n",
        "    megadocpos, megadocneg = \"\", \"\"\n",
        "    tpos, tneg = 0, 0\n",
        "    for text, label in trainingSet:\n",
        "        if label == '+':\n",
        "            tpos += 1\n",
        "            megadocpos += \" \" + text\n",
        "        elif label == '-':\n",
        "            tneg += 1\n",
        "            megadocneg += \" \" + text\n",
        "    megadocneg=megadocneg.lower()\n",
        "    megadocpos=megadocpos.lower()\n",
        "    #print(megadocpos)\n",
        "    #print(megadocneg)\n",
        "    c=megadocneg+ \" \"+megadocpos\n",
        "    c=c.split()\n",
        "    c=set(c)\n",
        "    #print(c,len(c))\n",
        "    a=megadocpos.split()\n",
        "    uniquepos=set(a)\n",
        "    b=megadocneg.split()\n",
        "    uniqueneg=set(b)\n",
        "    #print(a,\"\\n\",b)\n",
        "    print(f'posCount = {tpos}\\nnegCount = {tneg}')\n",
        "    ppos=tpos/(tpos+tneg)\n",
        "    pneg=tneg/(tpos+tneg)\n",
        "    print(f'ProbPos= {ppos}\\nProbNeg= {pneg}')\n",
        "    posbow = {word: a.count(word) for word in uniquepos }\n",
        "    negbow = {word: b.count(word) for word in uniqueneg }\n",
        "    print(posbow,\"total lenght\",sum(posbow.values()))\n",
        "    print(negbow,\"total lenght\",sum(negbow.values()))\n",
        "    print(f'V= {c}\\n|V|={len(c)}')\n",
        "    print(\"-----------------------------------------------------------------------\")\n",
        "    for text, label in testSet:\n",
        "        text=text.lower()\n",
        "        print(f\"Text document = ('{text} ','{label}')\")\n",
        "        text=text.split()\n",
        "        for i in text:\n",
        "          if i in c:\n",
        "                pwpos = (posbow.get(i, 0) + 1) / (sum(posbow.values()) + len(c))\n",
        "                pwneg = (negbow.get(i, 0) + 1) / (sum(negbow.values()) + len(c))\n",
        "                ppos *= pwpos\n",
        "                pneg *= pwneg\n",
        "                print(f'  word = \"{i}\" , wordconditionalProbPos = {pwpos:.6f} ,\\t wordconditionalProbNeg = {pwneg:.6f}')\n",
        "          else:\n",
        "                 print(f'  word = \"{i}\" , wordconditionalProbPos = Ignore ,\\t wordconditionalProbNeg = Ignore')\n",
        "\n",
        "        print(f'\\n docProbPos = {ppos:.6f} docProbneg = {pneg:.6f}')\n",
        "        print(\"  Inferred class = \", \"+\" if ppos > pneg else \"-\")\n",
        "        print(\"---------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "trainingSet = [('Boxing scene was a disappointment','-'),('No plot twists or great scenes','-'),('Great satire and great plot twists','+'),('Great scenes a great film','+')]\n",
        "testSet = [('Great disappointment indeed','?')]\n",
        "multinomialNaiveBayesClassifier(trainingSet,testSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.b"
      ],
      "metadata": {
        "id": "PX6FnlBst-c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binaryMultinomialNaiveBayesClassifier(trainingSet,testSet):\n",
        "  a,b=[],[]\n",
        "  tpos,tneg=0,0\n",
        "  for Document,clas in trainingSet:\n",
        "    #print(f'document = {Document} class = {clas}')\n",
        "    if clas=='+':\n",
        "      a.append(Document)\n",
        "      tpos+=1\n",
        "    elif clas=='-':\n",
        "      b.append(Document)\n",
        "      tneg+=1\n",
        "  print(f'posCount = {tpos}\\n negCount = {tneg}')\n",
        "  #print(a,\"next\",b)\n",
        "  X,Y=\"\",\"\"\n",
        "  for i,y in zip(a,b):\n",
        "    i=i.lower()\n",
        "    y=y.lower()\n",
        "    a1=i.split()\n",
        "    b1=y.split()\n",
        "    a1=set(a1)\n",
        "    b1=set(b1)\n",
        "    a1=\" \".join(a1)\n",
        "    b1=\" \".join(b1)\n",
        "    X+=\" \"+a1\n",
        "    Y+=\" \"+b1\n",
        "  l1=X.split()\n",
        "  l2=Y.split()\n",
        "  ppos,pneg=tpos / (tpos + tneg),tneg / (tpos + tneg)\n",
        "  #print(f\"megadoc of + = {X} and lenght= {len(l1)}\\nmegadoc of - = {Y} and lenght = {len(l2)}\")\n",
        "  print(f'Probpos = {ppos:.2f}  Probneg = {pneg:.2f}')\n",
        "  posbow = {word: l1.count(word) for word in l1}\n",
        "  negbow = {word: l2.count(word) for word in l2}\n",
        "  print(\"pos_bow= \",posbow)\n",
        "  print(\"neg_bow=\",negbow)\n",
        "  v=X+Y\n",
        "  V={}\n",
        "  v=v.split()\n",
        "  cnt=v\n",
        "  v=set(v)\n",
        "  for i in v:\n",
        "   V[i]=cnt.count(i)\n",
        "  print(\"V =\",V,\"|V|=\",len(V))\n",
        "  print(\"---------------------------------------------------------------------------\")\n",
        "\n",
        "  for text, _ in testSet:\n",
        "        text = text.lower()\n",
        "        words = text.split()\n",
        "        ppos,pneg=tpos / (tpos + tneg),tneg / (tpos + tneg)\n",
        "        print(f\"Text document = ('{text} ','{_}')\")\n",
        "        for word in words:\n",
        "            if word in V:\n",
        "                pwpos = (posbow.get(word, 0) + 1) / (sum(posbow.values()) + len(V))\n",
        "                pwneg = (negbow.get(word, 0) + 1) / (sum(negbow.values()) + len(V))\n",
        "                ppos *= pwpos\n",
        "                pneg *= pwneg\n",
        "                print(f'  word = \"{word}\" , wordconditionalProbPos = {pwpos:.6f} , wordconditionalProbNeg = {pwneg:.6f}')\n",
        "            else:\n",
        "                print(f'  word = \"{word}\" , wordconditionalProbPos = Ignore , wordconditionalProbNeg = Ignore')\n",
        "\n",
        "        print(f'\\n docProbPos = {ppos:.6f} \\tdocProbNeg = {pneg:.6f}')\n",
        "        print(\"  Inferred class = \", \"+\" if ppos > pneg else \"-\")\n",
        "        print(\"---------------------------------------------------------------------------\")\n",
        "\n",
        "trainingSet = [('Boxing scene was a disappointment','-'),('No plot twists or great scenes','-'),('Great satire and great plot twists','+'),('Great scenes a great film','+')]\n",
        "testSet = [('Great disappointment indeed','?')]\n",
        "binaryMultinomialNaiveBayesClassifier(trainingSet,testSet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX1TcyjAt-KS",
        "outputId": "83463198-1cfa-443a-c4f5-3f6bad1cf195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "posCount = 2\n",
            " negCount = 2\n",
            "Probpos = 0.50  Probneg = 0.50\n",
            "pos_bow=  {'great': 2, 'and': 1, 'plot': 1, 'satire': 1, 'twists': 1, 'a': 1, 'scenes': 1, 'film': 1}\n",
            "neg_bow= {'was': 1, 'boxing': 1, 'disappointment': 1, 'a': 1, 'scene': 1, 'great': 1, 'scenes': 1, 'plot': 1, 'or': 1, 'no': 1, 'twists': 1}\n",
            "V = {'great': 3, 'and': 1, 'was': 1, 'scenes': 2, 'boxing': 1, 'plot': 2, 'disappointment': 1, 'or': 1, 'satire': 1, 'no': 1, 'a': 2, 'scene': 1, 'twists': 2, 'film': 1} |V|= 14\n",
            "---------------------------------------------------------------------------\n",
            "Text document = ('great disappointment indeed ','?')\n",
            "  word = \"great\" , wordconditionalProbPos = 0.130435 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"disappointment\" , wordconditionalProbPos = 0.043478 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"indeed\" , wordconditionalProbPos = Ignore , wordconditionalProbNeg = Ignore\n",
            "\n",
            " docProbPos = 0.002836 \tdocProbNeg = 0.003200\n",
            "  Inferred class =  -\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.c"
      ],
      "metadata": {
        "id": "Ur1fPwnhxDt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binaryMultinomialNaiveBayesClassifier(trainingSet,testSet):\n",
        "  a,b=[],[]\n",
        "  tpos,tneg=0,0\n",
        "  for Document,clas in trainingSet:\n",
        "    #print(f'document = {Document} class = {clas}')\n",
        "    if clas=='+':\n",
        "      a.append(Document)\n",
        "      tpos+=1\n",
        "    elif clas=='-':\n",
        "      b.append(Document)\n",
        "      tneg+=1\n",
        "  print(f'posCount = {tpos}\\n negCount = {tneg}')\n",
        "  #print(a,\"next\",b)\n",
        "  X,Y=\"\",\"\"\n",
        "  for i,y in zip(a,b):\n",
        "    i=i.lower()\n",
        "    y=y.lower()\n",
        "    a1=i.split()\n",
        "    b1=y.split()\n",
        "    a1=set(a1)\n",
        "    b1=set(b1)\n",
        "    a1=\" \".join(a1)\n",
        "    b1=\" \".join(b1)\n",
        "    X+=\" \"+a1\n",
        "    Y+=\" \"+b1\n",
        "  l1=X.split()\n",
        "  l2=Y.split()\n",
        "  ppos,pneg=tpos / (tpos + tneg),tneg / (tpos + tneg)\n",
        "  #print(f\"megadoc of + = {X} and lenght= {len(l1)}\\nmegadoc of - = {Y} and lenght = {len(l2)}\")\n",
        "  print(f'Probpos = {ppos:.2f}  Probneg = {pneg:.2f}')\n",
        "  posbow = {word: l1.count(word) for word in l1}\n",
        "  negbow = {word: l2.count(word) for word in l2}\n",
        "  print(\"pos_bow= \",posbow)\n",
        "  print(\"neg_bow=\",negbow)\n",
        "  v=X+Y\n",
        "  V={}\n",
        "  v=v.split()\n",
        "  cnt=v\n",
        "  v=set(v)\n",
        "  for i in v:\n",
        "   V[i]=cnt.count(i)\n",
        "  print(\"V =\",V,\"|V|=\",len(V))\n",
        "  print(\"---------------------------------------------------------------------------\")\n",
        "  pred=[]\n",
        "  for text, _ in testSet:\n",
        "        text = text.lower()\n",
        "        words = text.split()\n",
        "        ppos,pneg=tpos / (tpos + tneg),tneg / (tpos + tneg)\n",
        "        print(f\"Text document = ('{text} ','{_}')\")\n",
        "        for word in words:\n",
        "            if word in V:\n",
        "                pwpos = (posbow.get(word, 0) + 1) / (sum(posbow.values()) + len(V))\n",
        "                pwneg = (negbow.get(word, 0) + 1) / (sum(negbow.values()) + len(V))\n",
        "                ppos *= pwpos\n",
        "                pneg *= pwneg\n",
        "                print(f'  word = \"{word}\" , wordconditionalProbPos = {pwpos:.6f} , wordconditionalProbNeg = {pwneg:.6f}')\n",
        "            else:\n",
        "                print(f'  word = \"{word}\" , wordconditionalProbPos = Ignore , wordconditionalProbNeg = Ignore')\n",
        "        print(f'\\n docProbPos = {ppos:.6f} \\tdocProbNeg = {pneg:.6f}')\n",
        "        print(\"  Inferred class = \", \"+\" if ppos > pneg else \"-\")\n",
        "        if ppos>pneg:\n",
        "          pred.append(\"+\")\n",
        "        else:\n",
        "          pred.append(\"-\")\n",
        "        print(\"---------------------------------------------------------------------------\")\n",
        "  tp = tn = fn = fp = 0\n",
        "\n",
        "  for i, (x, y) in enumerate(testSet):\n",
        "      if pred[i] == y and pred[i] == '+':\n",
        "          tp += 1\n",
        "      elif pred[i] == y and pred[i] == '-':\n",
        "          tn += 1\n",
        "      elif pred[i] != y and y == '+':\n",
        "          fn += 1\n",
        "      else:\n",
        "          fp += 1\n",
        "\n",
        "  print(f\"TP = {tp}  TN = {tn}  \\nFP = {fp}  FN = {fn}\")\n",
        "  accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "  precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "  recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "  f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "  print(f\"Accuracy= {accuracy}\")\n",
        "  print(f\"Precision= {precision}\")\n",
        "  print(f\"Recall= {recall}\")\n",
        "  print(f\"F1= {f1}\")\n",
        "trainingSet = [('Boxing scene was a disappointment','-'),('No plot twists or great scenes','-'),('Great satire and great plot twists','+'),('Great scenes a great film','+')]\n",
        "testSet = [('Great disappointment indeed','-'), ('What a great movie','+'), ('Great satire','+'), ('No plot twists or satire','-'), ('This movie was a disappointment','-'), ('great disappointment','-'), ('great boxing scenes','+'), ('great movie','+'), ('bad film','-'), ('nice film','+')]\n",
        "binaryMultinomialNaiveBayesClassifier(trainingSet,testSet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t04D3v-FpMRk",
        "outputId": "f5521ea0-15fa-4433-8a7f-71e9f6395d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "posCount = 2\n",
            " negCount = 2\n",
            "Probpos = 0.50  Probneg = 0.50\n",
            "pos_bow=  {'great': 2, 'and': 1, 'plot': 1, 'satire': 1, 'twists': 1, 'a': 1, 'scenes': 1, 'film': 1}\n",
            "neg_bow= {'was': 1, 'boxing': 1, 'disappointment': 1, 'a': 1, 'scene': 1, 'great': 1, 'scenes': 1, 'plot': 1, 'or': 1, 'no': 1, 'twists': 1}\n",
            "V = {'great': 3, 'and': 1, 'was': 1, 'scenes': 2, 'boxing': 1, 'plot': 2, 'disappointment': 1, 'or': 1, 'satire': 1, 'no': 1, 'a': 2, 'scene': 1, 'twists': 2, 'film': 1} |V|= 14\n",
            "---------------------------------------------------------------------------\n",
            "Text document = ('great disappointment indeed ','-')\n",
            "  word = \"great\" , wordconditionalProbPos = 0.130435 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"disappointment\" , wordconditionalProbPos = 0.043478 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"indeed\" , wordconditionalProbPos = Ignore , wordconditionalProbNeg = Ignore\n",
            "\n",
            " docProbPos = 0.002836 \tdocProbNeg = 0.003200\n",
            "  Inferred class =  -\n",
            "---------------------------------------------------------------------------\n",
            "Text document = ('what a great movie ','+')\n",
            "  word = \"what\" , wordconditionalProbPos = Ignore , wordconditionalProbNeg = Ignore\n",
            "  word = \"a\" , wordconditionalProbPos = 0.086957 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"great\" , wordconditionalProbPos = 0.130435 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"movie\" , wordconditionalProbPos = Ignore , wordconditionalProbNeg = Ignore\n",
            "\n",
            " docProbPos = 0.005671 \tdocProbNeg = 0.003200\n",
            "  Inferred class =  +\n",
            "---------------------------------------------------------------------------\n",
            "Text document = ('great satire ','+')\n",
            "  word = \"great\" , wordconditionalProbPos = 0.130435 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"satire\" , wordconditionalProbPos = 0.086957 , wordconditionalProbNeg = 0.040000\n",
            "\n",
            " docProbPos = 0.005671 \tdocProbNeg = 0.001600\n",
            "  Inferred class =  +\n",
            "---------------------------------------------------------------------------\n",
            "Text document = ('no plot twists or satire ','-')\n",
            "  word = \"no\" , wordconditionalProbPos = 0.043478 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"plot\" , wordconditionalProbPos = 0.086957 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"twists\" , wordconditionalProbPos = 0.086957 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"or\" , wordconditionalProbPos = 0.043478 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"satire\" , wordconditionalProbPos = 0.086957 , wordconditionalProbNeg = 0.040000\n",
            "\n",
            " docProbPos = 0.000001 \tdocProbNeg = 0.000001\n",
            "  Inferred class =  -\n",
            "---------------------------------------------------------------------------\n",
            "Text document = ('this movie was a disappointment ','-')\n",
            "  word = \"this\" , wordconditionalProbPos = Ignore , wordconditionalProbNeg = Ignore\n",
            "  word = \"movie\" , wordconditionalProbPos = Ignore , wordconditionalProbNeg = Ignore\n",
            "  word = \"was\" , wordconditionalProbPos = 0.043478 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"a\" , wordconditionalProbPos = 0.086957 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"disappointment\" , wordconditionalProbPos = 0.043478 , wordconditionalProbNeg = 0.080000\n",
            "\n",
            " docProbPos = 0.000082 \tdocProbNeg = 0.000256\n",
            "  Inferred class =  -\n",
            "---------------------------------------------------------------------------\n",
            "Text document = ('great disappointment ','-')\n",
            "  word = \"great\" , wordconditionalProbPos = 0.130435 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"disappointment\" , wordconditionalProbPos = 0.043478 , wordconditionalProbNeg = 0.080000\n",
            "\n",
            " docProbPos = 0.002836 \tdocProbNeg = 0.003200\n",
            "  Inferred class =  -\n",
            "---------------------------------------------------------------------------\n",
            "Text document = ('great boxing scenes ','+')\n",
            "  word = \"great\" , wordconditionalProbPos = 0.130435 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"boxing\" , wordconditionalProbPos = 0.043478 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"scenes\" , wordconditionalProbPos = 0.086957 , wordconditionalProbNeg = 0.080000\n",
            "\n",
            " docProbPos = 0.000247 \tdocProbNeg = 0.000256\n",
            "  Inferred class =  -\n",
            "---------------------------------------------------------------------------\n",
            "Text document = ('great movie ','+')\n",
            "  word = \"great\" , wordconditionalProbPos = 0.130435 , wordconditionalProbNeg = 0.080000\n",
            "  word = \"movie\" , wordconditionalProbPos = Ignore , wordconditionalProbNeg = Ignore\n",
            "\n",
            " docProbPos = 0.065217 \tdocProbNeg = 0.040000\n",
            "  Inferred class =  +\n",
            "---------------------------------------------------------------------------\n",
            "Text document = ('bad film ','-')\n",
            "  word = \"bad\" , wordconditionalProbPos = Ignore , wordconditionalProbNeg = Ignore\n",
            "  word = \"film\" , wordconditionalProbPos = 0.086957 , wordconditionalProbNeg = 0.040000\n",
            "\n",
            " docProbPos = 0.043478 \tdocProbNeg = 0.020000\n",
            "  Inferred class =  +\n",
            "---------------------------------------------------------------------------\n",
            "Text document = ('nice film ','+')\n",
            "  word = \"nice\" , wordconditionalProbPos = Ignore , wordconditionalProbNeg = Ignore\n",
            "  word = \"film\" , wordconditionalProbPos = 0.086957 , wordconditionalProbNeg = 0.040000\n",
            "\n",
            " docProbPos = 0.043478 \tdocProbNeg = 0.020000\n",
            "  Inferred class =  +\n",
            "---------------------------------------------------------------------------\n",
            "TP = 4  TN = 4  \n",
            "FP = 1  FN = 1\n",
            "Accuracy= 0.8\n",
            "Precision= 0.8\n",
            "Recall= 0.8\n",
            "F1= 0.8000000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2"
      ],
      "metadata": {
        "id": "DzfedCy33SjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def sentimentAnalyzer(string):\n",
        "    blob = TextBlob(string)\n",
        "    sentiment = blob.sentiment\n",
        "    print(f\"String= {string}\\n\")\n",
        "    print(sentiment)\n",
        "    polarity = sentiment.polarity\n",
        "    subjectivity = sentiment.subjectivity\n",
        "    if polarity > 0.1:\n",
        "        print(\"Positive sentiment \")\n",
        "    elif polarity < -0.1:\n",
        "        print(\"Negative sentiment \")\n",
        "    else:\n",
        "        print(\"Neutral sentiment \")\n",
        "\n",
        "    print(f\"Subjectivity: {subjectivity}\")\n",
        "    print(\"------------------------------------\\n\")\n",
        "\n",
        "sentimentAnalyzer(\"NLP is cool\")\n",
        "sentimentAnalyzer(\"NLP is cool and useful\")\n",
        "sentimentAnalyzer(\"NLP is hard\")\n",
        "sentimentAnalyzer(\"NLP is hard and useless\")\n",
        "sentimentAnalyzer(\"NLP stands for Natural Language Processing\")\n",
        "sentimentAnalyzer(\"NLP stands for Natural Language Processing and it can be hard sometimes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRW2oKXb13wG",
        "outputId": "51d85960-b8e6-4f68-c039-d019b5c21078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "String= NLP is cool\n",
            "\n",
            "Sentiment(polarity=0.35, subjectivity=0.65)\n",
            "Positive sentiment \n",
            "Subjectivity: 0.65\n",
            "------------------------------------\n",
            "\n",
            "String= NLP is cool and useful\n",
            "\n",
            "Sentiment(polarity=0.32499999999999996, subjectivity=0.325)\n",
            "Positive sentiment \n",
            "Subjectivity: 0.325\n",
            "------------------------------------\n",
            "\n",
            "String= NLP is hard\n",
            "\n",
            "Sentiment(polarity=-0.2916666666666667, subjectivity=0.5416666666666666)\n",
            "Negative sentiment \n",
            "Subjectivity: 0.5416666666666666\n",
            "------------------------------------\n",
            "\n",
            "String= NLP is hard and useless\n",
            "\n",
            "Sentiment(polarity=-0.39583333333333337, subjectivity=0.37083333333333335)\n",
            "Negative sentiment \n",
            "Subjectivity: 0.37083333333333335\n",
            "------------------------------------\n",
            "\n",
            "String= NLP stands for Natural Language Processing\n",
            "\n",
            "Sentiment(polarity=0.1, subjectivity=0.4)\n",
            "Neutral sentiment \n",
            "Subjectivity: 0.4\n",
            "------------------------------------\n",
            "\n",
            "String= NLP stands for Natural Language Processing and it can be hard sometimes\n",
            "\n",
            "Sentiment(polarity=-0.09583333333333334, subjectivity=0.4708333333333333)\n",
            "Neutral sentiment \n",
            "Subjectivity: 0.4708333333333333\n",
            "------------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}